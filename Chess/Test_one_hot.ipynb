{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test one hot.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QgYfW0d8T9xm"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import datetime\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PTdezJDWYfZ"
      },
      "source": [
        "import os\n",
        "os.chdir(\"/content/drive/My Drive/Colab Notebooks/leela/test3/AlphaZero_Chess/src\")\n",
        "\n",
        "from policy_index import policy_index\n",
        "\n",
        "action_size = len(policy_index)\n",
        "num_resblock = 4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "binL451aJeEt"
      },
      "source": [
        "os.chdir(\"/content/\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBnxY8LOb9RL"
      },
      "source": [
        "from torch.nn import MSELoss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g66wFFSAcFBu"
      },
      "source": [
        "# get data from Oscar, might need to rewrite to fit the data structure he has\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, data, target, transform=None):\n",
        "        self.data = torch.from_numpy(data).float()\n",
        "        self.target = torch.from_numpy(target).long()\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.target[index]\n",
        "        \n",
        "        if self.transform:\n",
        "            x = self.transform(x)\n",
        "            \n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "numpy_data = np.random.randn(100,112, 8, 8) # 10 samples, image size = 224 x 224 x 3\n",
        "numpy_target = np.random.randint(0,5,size=(100))\n",
        "\n",
        "dataset = MyDataset(numpy_data, numpy_target)\n",
        "loader = DataLoader(dataset, batch_size=5, shuffle=True, num_workers=2, pin_memory=False)  # Running on CPU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dYozbMMWeG2"
      },
      "source": [
        "# convblock for doing convolutional work\n",
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.action_size = action_size\n",
        "        self.conv1 = nn.Conv2d(112, 256, 3, stride=1, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(256)\n",
        "\n",
        "    def forward(self, s):\n",
        "        s = s.view(-1, 112, 8, 8)  # batch_size x channels x board_x x board_y\n",
        "        s = F.relu(self.bn1(self.conv1(s)))\n",
        "        return s\n",
        "\n",
        "\n",
        "# Resblock to do residual block: x + conv output (x)\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, inplanes=256, planes=256, stride=1, downsample=None):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        out = self.conv1(x)\n",
        "        out = F.relu(self.bn1(out))\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out += residual\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "# final FC layers\n",
        "# get more layer in the last round + flatten\n",
        "class OutBlock(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(OutBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(256, 1, kernel_size=1) # value head\n",
        "        self.bn = nn.BatchNorm2d(1)\n",
        "        self.fc1 = nn.Linear(8*8, 64)\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        \n",
        "        # self.conv1 = nn.Conv2d(256, 128, kernel_size=1) # policy head\n",
        "        # self.bn1 = nn.BatchNorm2d(128)\n",
        "        # self.logsoftmax = nn.LogSoftmax(dim=1)\n",
        "        # self.fc = nn.Linear(8*8*128, 8*8*73)\n",
        "    \n",
        "    def forward(self,s):\n",
        "        v = F.relu(self.bn(self.conv(s))) # value head\n",
        "        v = v.view(-1, 8*8)  # batch_size X channel X height X width\n",
        "        v = F.relu(self.fc1(v))\n",
        "        v = F.relu(self.fc2(v))\n",
        "        \n",
        "        # p = F.relu(self.bn1(self.conv1(s))) # policy head\n",
        "        # p = p.view(-1, 8*8*128)\n",
        "        # p = self.fc(p)\n",
        "        # p = self.logsoftmax(p).exp()\n",
        "        return v\n",
        "    \n",
        "# stacking conv block + a bunch of res block + out block\n",
        "class ChessNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ChessNet, self).__init__()\n",
        "        self.conv = ConvBlock()\n",
        "        for block in range(num_resblock):\n",
        "            setattr(self, \"res_%i\" % block,ResBlock())\n",
        "        self.outblock = OutBlock()\n",
        "    \n",
        "    def forward(self,s):\n",
        "        s = self.conv(s)\n",
        "        for block in range(num_resblock):\n",
        "            s = getattr(self, \"res_%i\" % block)(s)\n",
        "        s = self.outblock(s)\n",
        "        return s\n",
        "        \n",
        "    \n",
        "# training\n",
        "def train(net, dataset, epoch_start=0, epoch_stop=20, cpu=0):\n",
        "    torch.manual_seed(cpu)\n",
        "    cuda = torch.cuda.is_available()\n",
        "    net.train()\n",
        "    criterion = MSELoss()\n",
        "    optimizer = optim.Adam(net.parameters(), lr=0.003)\n",
        "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[100,200,300,400], gamma=0.2)\n",
        "    \n",
        "    # train_set = board_data(dataset)\n",
        "    # train_loader = DataLoader(train_set, batch_size=30, shuffle=True, num_workers=0, pin_memory=False)\n",
        "    train_loader = dataset\n",
        "    losses_per_epoch = []\n",
        "    for epoch in range(epoch_start, epoch_stop):\n",
        "        scheduler.step()\n",
        "        total_loss = 0.0\n",
        "        losses_per_batch = []\n",
        "        for i,data in enumerate(train_loader,0):\n",
        "            state, value = data\n",
        "            if cuda:\n",
        "                state, value = state.cuda().float(), value.cuda().float()\n",
        "            optimizer.zero_grad()\n",
        "            value_pred = net(state) # policy_pred = torch.Size([batch, 4672]) value_pred = torch.Size([batch, 1])\n",
        "            # print(value_pred, value)\n",
        "            # print(value_pred.shape, value.shape)\n",
        "            loss = criterion(value_pred[:,0], value)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            losses_per_batch.append(loss.item())\n",
        "        try:\n",
        "          losses_per_epoch.append(np.mean(losses_per_batch))\n",
        "        except:\n",
        "          losses_per_epoch.append(0.1)\n",
        "        if len(losses_per_epoch) > 100:\n",
        "            if abs(sum(losses_per_epoch[-4:-1])/3-sum(losses_per_epoch[-16:-13])/3) <= 0.01:\n",
        "                break\n",
        "\n",
        "    plt.figure(figsize=(12,8))\n",
        "    # ax = fig.add_subplot(222)\n",
        "    plt.scatter([e for e in range(1,epoch_stop+1,1)], losses_per_epoch)\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss per batch\")\n",
        "    plt.title(\"Loss vs Epoch\")\n",
        "    print('Finished Training')\n",
        "    plt.savefig(os.path.join(\"./\", \"Loss_vs_Epoch_%s.png\" % datetime.datetime.today().strftime(\"%Y-%m-%d\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "id": "OHpkfy9XcMGH",
        "outputId": "49c6907e-f96a-4f9c-f58c-a1cfc25a1a65"
      },
      "source": [
        "# from alpha_net import ChessNet, train\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "def train_chessnet(net_to_train= None ,save_as= \"weights.pth.tar\"):\n",
        "    # gather data\n",
        "    # data_path = \"./datasets/iter1/\"\n",
        "    # datasets = []\n",
        "    # for idx,file in enumerate(os.listdir(data_path)):\n",
        "    #     filename = os.path.join(data_path,file)\n",
        "    #     with open(filename, 'rb') as fo:\n",
        "    #         datasets.extend(pickle.load(fo, encoding='bytes'))\n",
        "    \n",
        "    # data_path = \"./datasets/iter0/\"\n",
        "    # for idx,file in enumerate(os.listdir(data_path)):\n",
        "    #     filename = os.path.join(data_path,file)\n",
        "    #     with open(filename, 'rb') as fo:\n",
        "    #         datasets.extend(pickle.load(fo, encoding='bytes'))\n",
        "    \n",
        "    # datasets = np.array(datasets)\n",
        "    \n",
        "    # train net\n",
        "\n",
        "    datasets = loader\n",
        "    net = ChessNet()\n",
        "    cuda = torch.cuda.is_available()\n",
        "    if cuda:\n",
        "        net.cuda()\n",
        "\n",
        "    if net_to_train:\n",
        "        current_net_filename = os.path.join(\"./model_data/\",\\\n",
        "                                        net_to_train)\n",
        "        checkpoint = torch.load(current_net_filename)\n",
        "        net.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "    train(net,datasets)\n",
        "    # save results\n",
        "    # torch.save({'state_dict': net.state_dict()}, os.path.join(\"./model/\",\\\n",
        "    #                                 save_as))\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    train_chessnet()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:134: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Finished Training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHj8M9oteg4G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqXzAB5ke4Pa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}